---
layout: post
title: Better Interfaces in Bioinformatics
tags:
 - hide
---

In case this pops up in the github repo, this was an earlier version
of another essay (see HTML comments).

<!---
# Better Interfaces in Bioinformatics

Day to day bioinformatics involves interfacing many programs to
process data. We end up with some refinement of the data from which we
extract biological meaning through data analysis. Given how much
interfacing of different programs this involves, the concept of
"interfacing" undergoes very little thought or optimization.

For what I imagine are primarily historical reasons, bioinformatics
programs are primarily interfaced through scripts that make system
calls, usually invoking a subprocess that writes to a file. Actual
functionality like sequence assembly, mapping, and alignment occurs in
large command-line programs like
[velvet](https://github.com/dzerbino/velvet),
[bwa](https://github.com/lh3/bwa), or
[BLAST](http://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=Download). Each
program writes output to a file, from which another program or script
parses and extracts data. Then this process repeats itself as data is
further refined. This is the de facto interfacing pattern in
bioinformatics (I think of this as the **system-call, file
system-state** pattern):

  1. Functionality is implemented by large command line programs.

  2. Calls are made to large programs through a command line interface.

  3 State (even intermediate state) is stored via a file system.

Under this pattern
[state](http://en.wikipedia.org/wiki/State_(computer_science)) is
stored on the file system, and functionality is achieved by system
calls that pass string command line arguments. Storing state on the
file system (where it is highly mutable, and access is extremely slow)
is clunky, as is the additional parsing needed at every point of this
interface pattern.

Nevertheless, this has been an acceptable standard interfacing pattern
for most *routine* bioinformatics tasks. Yet, I think the time has
come to discuss how limiting and flawed it is to solely rely on this
interface pattern for bioinformatics. Bioinformaticians should embrace
the shared library and foreign function interfaces more regularly, and
developers of large software programs should begin to design more
accessible interfaces.

## Benefits of the Current Pattern

This current pattern has benefits. First, it's intimately tied to the
[Unix Philosophy](http://www.faqs.org/docs/artu/ch01s06.html), and
programs can be interfaced through Unix pipes. Piping output to
another program's standard input stream is a wonderfully elegant
solution, as it avoids the most common hardware bottleneck: the
disk. As an aside, every programmer should know [latency
numbers](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html)
associated with disk activities to [really understand how costly this
is (zoom into this image)](http://i.imgur.com/X1Hi1.gif).

Also, one could easily redirect output streams to a file which
provides an excellent method of debugging and interrogating
intermediate output. Conceptually, writing, reading, and parsing files
is easy for a new programmer from another discipline to understand.

## Disadvantages of the Current Pattern and Alternatives

However, this pattern is not well suited to tackle large, novel
bioinformatics tasks. Furthermore, our field is plagued by developers
rewriting rather than recycling core functionality in large pieces of
software, and I believe this is at least partially due to the extreme
limitations of the current pattern.

Suppose I needed to call Muscle on thousands of sequences separately
to tackle a particular project. The avoidable computational bottleneck
in calling a Muscle subprocess is having it read a FASTA file directly
from the disk. Suppose instead of calling Muscle through a subprocess
(as [BioPython
does](https://github.com/biopython/biopython/blob/master/Bio/Align/Applications/_Muscle.py)),
we compiled Muscle as a shared library, and we were able to call core
alignment functions directly on strings of sequences (or, more likely,
`char *`). Rather than open an entire subprocess, deal with command
line arguments, have Muscle read from the disk, and parse the output
from Muscle, I could directly call an alignment function and receive a
pointer to a structure of results.

Even if there were little overhead in opening a subprocess, using
foreign function interfaces is just cleaner and more elegant. Storing
state through files is messy. After a system call to Muscle from a
wrapper script, Muscle writes its output to a file (or, more
efficiently, an input stream) in a particular format, which the
processing script then needs to parse and handle. This is all
avoidable inelegance with better program interfacing practices.

## Foreign Function Interfaces

Foreign Foreign Interfaces to shared libraries are rare in
bioinformatics, likely due to [path
dependence](http://en.wikipedia.org/wiki/Path_dependence) more than
impracticality. Large bioinformatics programs like aligners,
assemblers, and mappers are most commonly written in C or C++, which
have standard ways of compiling object files as shared
libraries. Nonetheless, the bulk of interaction with these programs is
done via the clunky system call interface.

So what is a foreign function interface? It's an interface through
which one programming language can call functions of another (foreign)
language. It's related to an Application Programming Interface (API),
which is a more general term referring to a type of protocol that
allows separate programs to interface. FFIs are mostly lower level
than APIs. For example, consider a small C library that does
Smith-Waterman alignment. A core function like `sw_align(...)` could
be invoked by directly passing pointers to character arrays via
Python's ctypes module â€” this would be an example of a foreign
function interface. 

The benefit of the FFI is that lower-level functions can be accessed
much more readily. Novel bioinformatics tasks are novel because
existing programs can't solve them in their current
implementations. Being able to leverage core parts of existing tools
through FFIs is an elegant way of recycle code and saving time by not
reinventing the wheel.

## FFI in Practice

So far, this has been largely a theoretical discussion about why FFIs
are good technology and why they should be adopted in
bioinformatics. Recently I had to tackle a relatively novel
bioinformatics problem and I was able to leverage shared libraries and
FFIs quite well.

The problem was that I needed to assemble many sets of sequences for a
pet project. I really wanted to avoid needlessly writing FASTA files
of these sets of sequences to disk, as this is quite costly. However,
most assemblers were designed solely to be interfaced through the
command line. The inelegance of writing thousands of files, making
thousands of system calls to an assembler, then reading and parsing
the results not appealing, so I wrote
[pyfermi](http://github.com/vsbuffalo/pyfermi), a simple Python
interface to [Heng Li's](http://lh3lh3.users.sourceforge.net/) [Fermi
assembler](https://github.com/lh3/fermi) (note that this software is
experimental, so use it with caution). First off, I couldn't have done
this without Heng's excellent assembler, clean code, and advice, so I
owe him a debt of gratitude. The Fermi source has a beautiful example
of high-level functions that can be interfaced with relative ease: see
the `fm6_api_*` functions used in
[example.c](https://github.com/lh3/fermi/blob/master/example.c).

I was able to write a few extra C functions in pyfermi (mostly to deal
with `void *` necessary because Python's ctypes can't handle foreign
types AFAIK), and
[compile](https://github.com/vsbuffalo/pyfermi/blob/master/Makefile)
Fermi as a shared library. 

## Compiling Shared Libraries

In the future, I plan on complementing this article with more
technical pieces on static and shared libraries, dynamic loading and
linking, how to design good interfaces, etc. However, I'll cover some
basic resources here.

For a great introduction to shared libraries, I recommend ["The Inside
Story On Shared Libraries and Dynamic
Loading"](http://bit.ly/14jcKTt). IBM DeveloperWorks also has a nice
article on the [Anatomy of Linux dynamic
libraries](http://www.ibm.com/developerworks/library/l-dynamic-libraries/index.html).

As far as Bioinformatics scripting languages, I primarily work with
Python and R. R handles calls to shared libraries extremely well: see
[Writing R
Extensions](http://cran.r-project.org/doc/manuals/R-exts.html) for an
excellent treatment of this (this is how my Bioconductor package
[qrqc](http://bioconductor.org/packages/release/bioc/html/qrqc.html)
interfaces R and C). Python's [ctypes
module](http://docs.python.org/library/ctypes.html) is what I
primarily use with Python, but [Cython](http://cython.org/) is another
good option (and used by respected bioinformatics projects like
[pysam](http://code.google.com/p/pysam/)).

## Future Directions

Bioinformatics would benefit from a more critical look at
interfacing. Bioinformaticians are surprisingly willing to put up with
libraries that poorly follow file format specifications, making even
basic command line interfacing more troubling than it should be. Code
is rarely modular, or if it is, the interfaces are not documented
thoroughly enough to be useful to downstream developers
([AMOS](http://sourceforge.net/apps/mediawiki/amos/index.php?title=AMOS),
"A Modular, Open-Source whole genome assembler", is an example of a
promising modular project that lacks the high-level documentation most
developers need). Bioinformatics tasks will grow significantly more
complicated in coming decades, as huge diverse data sets will be
processed, combined, and analyzed. These problems will require
higher-level interfacing and code, and we need to begin optimizing our
interfaces and developing more modular code to tackle these problems.
-->